// Define the project directory
projectDir = "$baseDir"

params {
    // Use absolute paths and handle spaces in paths
    id_path = "${projectDir}/data/sample_id.xlsx"
    data1_path = "${projectDir}/data/data1.xlsx"
    data2_path = "${projectDir}/data/data2.xlsx"

    // Output directory
    outdir = "${projectDir}/analysis"
}

process {
    conda = true
    executor = 'local'
    echo = true
    
    // Add debugging
    beforeScript = { 
        println "Running process in: ${task.workDir}"
        println "Input files: ${task.inputs}"
    }
}

// Add more detailed logging
trace {
    enabled = true
    file = "${projectDir}/pipeline_trace.txt"
    overwrite = true
    fields = 'task_id,hash,native_id,process,tag,name,status,exit,submit,start,complete,duration,realtime,%cpu,%mem,rss,vmem,peak_rss,peak_vmem,rchar,wchar,syscr,syscw,read_bytes,write_bytes,workdir,error_action'
}

// Enable debugging information
debug {
    enabled = true
}

singularity {
    enabled = false
}

docker {
    enabled = false
}

// Print some helpful information when the pipeline starts
manifest {
    description = 'Data analysis pipeline'
    version = '1.0'
}

// Add trace configuration with overwrite enabled
trace {
    enabled = true
    file = "${projectDir}/pipeline_trace.txt"
    overwrite = true    // Add this line to allow overwriting
}

report {
    enabled = true
    file = "${projectDir}/pipeline_report.html"
    overwrite = true    // Add this line to allow overwriting
}